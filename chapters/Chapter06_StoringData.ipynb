{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_absolute_url(base_url: str, source: str) -> str:\n",
    "    is_absolute = source.startswith((\"http://\", \"https://\"))\n",
    "    has_external_domain = is_absolute and base_url not in source\n",
    "\n",
    "    if has_external_domain:\n",
    "        return None\n",
    "\n",
    "    if is_absolute:\n",
    "        url = source.replace(\"www.\", \"\")\n",
    "    elif source.startswith(\"www.\"):\n",
    "        url = urljoin(\"http://\", source.replace(\"www.\", \"\"))\n",
    "    else:\n",
    "        url = urljoin(base_url, source)\n",
    "\n",
    "    parsed = urlparse(url)\n",
    "    return f\"{parsed.scheme}://{parsed.netloc}{parsed.path}\"\n",
    "\n",
    "\n",
    "def get_download_path(base_url: str, absolute_url: str, download_dir: str):\n",
    "    if not base_url.endswith(\"/\"):\n",
    "        base_url += \"/\"\n",
    "\n",
    "    relative_path = absolute_url.replace(base_url, \"\")\n",
    "    download_path = Path(download_dir) / relative_path\n",
    "\n",
    "    if not os.path.exists(download_path.parent):\n",
    "        os.makedirs(download_path.parent)\n",
    "\n",
    "    return download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = \"downloaded\"\n",
    "base_url = \"http://pythonscraping.com\"\n",
    "url = \"http://www.pythonscraping.com\"\n",
    "\n",
    "html = urlopen(url)\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "download_list = bs.find_all(src=True)\n",
    "\n",
    "for download in download_list:\n",
    "    if file_url := get_absolute_url(base_url, download[\"src\"]):\n",
    "        print(file_url)\n",
    "        download_path = get_download_path(base_url, file_url, download_dir)\n",
    "        urlretrieve(file_url, download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.csv\", \"w+\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow((\"number\", \"number plus 2\", \"number times 2\"))\n",
    "    for i in range(10):\n",
    "        writer.writerow((i, i + 2, i * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"scraping.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    with open(\"./create_table.sql\", \"r\") as sqlFile:\n",
    "        create_table_command = sqlFile.read()\n",
    "\n",
    "    cursor.execute(create_table_command)\n",
    "    conn.commit()\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "msg = MIMEText(\"The body of the email is here\")\n",
    "\n",
    "msg[\"Subject\"] = \"An Email Alert\"\n",
    "msg[\"From\"] = \"ryan@pythonscraping.com\"\n",
    "msg[\"To\"] = \"webmaster@pythonscraping.com\"\n",
    "\n",
    "s = smtplib.SMTP(\"localhost\")\n",
    "s.send_message(msg)\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "\n",
    "\n",
    "def sendMail(subject, body):\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = \"christmas_alerts@pythonscraping.com\"\n",
    "    msg[\"To\"] = \"ryan@pythonscraping.com\"\n",
    "\n",
    "    s = smtplib.SMTP(\"localhost\")\n",
    "    s.send_message(msg)\n",
    "    s.quit()\n",
    "\n",
    "\n",
    "bs = BeautifulSoup(urlopen(\"https://isitchristmas.com/\"), \"html.parser\")\n",
    "while bs.find(\"a\", {\"id\": \"answer\"}).attrs[\"title\"] == \"NO\":\n",
    "    print(\"It is not Christmas yet.\")\n",
    "    time.sleep(3600)\n",
    "    bs = BeautifulSoup(urlopen(\"https://isitchristmas.com/\"), \"html.parser\")\n",
    "sendMail(\n",
    "    \"It's Christmas!\",\n",
    "    \"According to http://itischristmas.com, it is Christmas!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
